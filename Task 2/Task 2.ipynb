{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNo+gV8q3f8cm3oy8Bphfa2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manas-Todi/STYLE-SWAP/blob/main/Task%202/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vUHqcFxpK8FS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QncCk8v8A5v",
        "outputId": "7da7d953-2791-4261-9ceb-64c2a4f80e3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sharp_img = torch.empty(350,3,256,256)\n",
        "for i,pic in enumerate(sorted(os.listdir(\"/content/drive/MyDrive/blur_dataset_scaled/sharp\"))):\n",
        "    img=torchvision.io.read_image(path=os.path.join(\"/content/drive/MyDrive/blur_dataset_scaled/sharp\", pic))\n",
        "    img=torchvision.transforms.Resize((256,256))(img)\n",
        "    sharp_img[i,:,:,:]=img"
      ],
      "metadata": {
        "id": "RJhm7RyQBbW1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motion_blur_img = torch.empty(350,3,256,256)\n",
        "for i,pic in enumerate(sorted(os.listdir(\"/content/drive/MyDrive/blur_dataset_scaled/motion_blurred\"))):\n",
        "    img=torchvision.io.read_image(path=os.path.join(\"/content/drive/MyDrive/blur_dataset_scaled/motion_blurred\", pic))\n",
        "    img=torchvision.transforms.Resize((256,256))(img)\n",
        "    motion_blur_img[i,:,:,:]=img"
      ],
      "metadata": {
        "id": "XPTtyCWqEDde"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defocus_blur_img = torch.empty(350,3,256,256)\n",
        "for i,pic in enumerate(sorted(os.listdir(\"/content/drive/MyDrive/blur_dataset_scaled/defocused_blurred\"))):\n",
        "    img=torchvision.io.read_image(path=os.path.join(\"/content/drive/MyDrive/blur_dataset_scaled/defocused_blurred\", pic))\n",
        "    img=torchvision.transforms.Resize((256,256))(img)\n",
        "    defocus_blur_img[i,:,:,:]=img"
      ],
      "metadata": {
        "id": "AKsMj2KRvtI9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class unet(nn.Module):\n",
        "\t#  Determine what layers and their order in CNN object\n",
        "    def __init__(self):\n",
        "        super(unet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3,padding =1)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding =1)\n",
        "\n",
        "        self.avg_pool1 = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,padding =1)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding =1)\n",
        "\n",
        "        self.avg_pool2 = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,padding =1)\n",
        "        self.conv_layer6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,padding =1)\n",
        "\n",
        "        self.avg_pool3 = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer7= nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,padding =1)\n",
        "        self.conv_layer8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding =1)\n",
        "\n",
        "        self.avg_pool4 = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer9= nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3,padding =1)\n",
        "        self.conv_layer10 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3,padding =1)\n",
        "\n",
        "        self.up_conv_1= nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2,stride=2,padding =0)\n",
        "        # contatenate here\n",
        "        self.conv_layer11= nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3,padding =1)\n",
        "        self.conv_layer12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding =1)\n",
        "\n",
        "        self.up_conv_2= nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2,stride=2,padding =0)\n",
        "        # contatenate here\n",
        "        self.conv_layer13= nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3,padding =1)\n",
        "        self.conv_layer14= nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,padding =1)\n",
        "\n",
        "        self.up_conv_3= nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2,stride=2,padding =0)\n",
        "        # contatenate here\n",
        "        self.conv_layer15= nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3,padding =1)\n",
        "        self.conv_layer16= nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding =1)\n",
        "\n",
        "        self.up_conv_4= nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2,stride=2,padding =0)\n",
        "        # contatenate here\n",
        "        self.conv_layer17= nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3,padding =1)\n",
        "        self.conv_layer18 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding =1)\n",
        "\n",
        "        self.output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1)\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = F.relu(out)\n",
        "        gap1 = self.conv_layer2(out)\n",
        "        out = F.relu(gap1)\n",
        "        out = self.avg_pool1(out)\n",
        "        out = self.conv_layer3(out)\n",
        "        out = F.relu(out)\n",
        "        gap2 = self.conv_layer4(out)\n",
        "        out = F.relu(gap2)\n",
        "        out = self.avg_pool2(out)\n",
        "        out = self.conv_layer5(out)\n",
        "        out = F.relu(out)\n",
        "        gap3 = self.conv_layer6(out)\n",
        "        out = F.relu(gap3)\n",
        "        out = self.avg_pool3(out)\n",
        "        out = self.conv_layer7(out)\n",
        "        out = F.relu(out)\n",
        "        gap4 = self.conv_layer8(out)\n",
        "        out = F.relu(gap4)\n",
        "\n",
        "        out = self.avg_pool4(out)\n",
        "        out = self.conv_layer9(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv_layer10(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out=self.up_conv_1(out)\n",
        "        out=torch.cat((gap4,out),1)\n",
        "        out = self.conv_layer11(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv_layer12(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out=self.up_conv_2(out)\n",
        "        out=torch.cat((gap3,out),1)\n",
        "        out = self.conv_layer13(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv_layer14(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out=self.up_conv_3(out)\n",
        "        out=torch.cat((gap2,out),1)\n",
        "        out = self.conv_layer15(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv_layer16(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out=self.up_conv_4(out)\n",
        "        out=torch.cat((gap1,out),1)\n",
        "        out = self.conv_layer17(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv_layer18(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.output(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "y7I7C8HRBYR5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet= unet()"
      ],
      "metadata": {
        "id": "X0GZI4uO3smm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))\n",
        "unet.to(device_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S16tIvG3Ejgi",
        "outputId": "6239ddb5-ba85-428a-b521-a263971c6070"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unet(\n",
              "  (conv_layer1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avg_pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv_layer3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avg_pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv_layer5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avg_pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv_layer7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (avg_pool4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (conv_layer9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (up_conv_1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv_layer11): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (up_conv_2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv_layer13): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (up_conv_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv_layer15): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (up_conv_4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv_layer17): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_layer18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (output): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(unet, input_size = (3, 256, 256), batch_size = -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efaaYA3m7RNQ",
        "outputId": "7f84841c-84bf-40e2-fe35-4dfb07c8d0e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "            Conv2d-2         [-1, 64, 256, 256]          36,928\n",
            "         AvgPool2d-3         [-1, 64, 128, 128]               0\n",
            "            Conv2d-4        [-1, 128, 128, 128]          73,856\n",
            "            Conv2d-5        [-1, 128, 128, 128]         147,584\n",
            "         AvgPool2d-6          [-1, 128, 64, 64]               0\n",
            "            Conv2d-7          [-1, 256, 64, 64]         295,168\n",
            "            Conv2d-8          [-1, 256, 64, 64]         590,080\n",
            "         AvgPool2d-9          [-1, 256, 32, 32]               0\n",
            "           Conv2d-10          [-1, 512, 32, 32]       1,180,160\n",
            "           Conv2d-11          [-1, 512, 32, 32]       2,359,808\n",
            "        AvgPool2d-12          [-1, 512, 16, 16]               0\n",
            "           Conv2d-13         [-1, 1024, 16, 16]       4,719,616\n",
            "           Conv2d-14         [-1, 1024, 16, 16]       9,438,208\n",
            "  ConvTranspose2d-15          [-1, 512, 32, 32]       2,097,664\n",
            "           Conv2d-16          [-1, 512, 32, 32]       4,719,104\n",
            "           Conv2d-17          [-1, 512, 32, 32]       2,359,808\n",
            "  ConvTranspose2d-18          [-1, 256, 64, 64]         524,544\n",
            "           Conv2d-19          [-1, 256, 64, 64]       1,179,904\n",
            "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
            "  ConvTranspose2d-21        [-1, 128, 128, 128]         131,200\n",
            "           Conv2d-22        [-1, 128, 128, 128]         295,040\n",
            "           Conv2d-23        [-1, 128, 128, 128]         147,584\n",
            "  ConvTranspose2d-24         [-1, 64, 256, 256]          32,832\n",
            "           Conv2d-25         [-1, 64, 256, 256]          73,792\n",
            "           Conv2d-26         [-1, 64, 256, 256]          36,928\n",
            "           Conv2d-27          [-1, 3, 256, 256]             195\n",
            "================================================================\n",
            "Total params: 31,031,875\n",
            "Trainable params: 31,031,875\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 320.50\n",
            "Params size (MB): 118.38\n",
            "Estimated Total Size (MB): 439.63\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.cat((motion_blur_img,defocus_blur_img),0)\n",
        "y=torch.cat((sharp_img,sharp_img),0)\n",
        "print(X.shape,y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXif84Ea6Vzv",
        "outputId": "548900fb-85ff-4865-96da-d2e5e2b8b2da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([700, 3, 256, 256]) torch.Size([700, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test= X[:600,:,:,:]\n",
        "x_train=X[600:,:,:,:]\n",
        "y_test= y[:600,:,:,:]\n",
        "y_train=y[600:,:,:,:]\n",
        "print(x_test.shape,x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq1SVDKe7JuL",
        "outputId": "9909b7dd-f105-41c5-965a-ff36d31e8ffd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([600, 3, 256, 256]) torch.Size([100, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
        "num_epochs=10\n",
        "best_loss=10000\n",
        "for epoch in range(num_epochs):\n",
        "    i=0\n",
        "    for data in x_train:\n",
        "        img=torch.reshape(data, (1,3,256,256)).requires_grad_(True)\n",
        "        img = img.to(device_name)\n",
        "        true=y_train[i]\n",
        "        true=torch.reshape(true,(1,3,256,256)).requires_grad_(True)\n",
        "        true=true.to(device_name)\n",
        "\n",
        "        output = unet(img)\n",
        "        loss = criterion(true, img)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        i+=1\n",
        "\n",
        "    unet.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        j=0\n",
        "        for data in x_test:\n",
        "            img=torch.reshape(data, (1,3,256,256)).requires_grad_(True)\n",
        "            img = img.to(device_name)\n",
        "            true=y_test[j]\n",
        "            true=torch.reshape(true,(1,3,256,256)).requires_grad_(True)\n",
        "            true=true.to(device_name)\n",
        "\n",
        "            output = unet(img)\n",
        "            loss = criterion(true, img)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    val_loss /= len(x_test)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_model_wts = unet.state_dict()\n",
        "\n",
        "torch.save(best_model_wts, 'best_model.pth')\n",
        "print('Model with the least loss saved.')"
      ],
      "metadata": {
        "id": "0kxLqT49ET9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5d2979-f3c4-4479-a3c9-8ddf890d23a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [2/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [3/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [4/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [5/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [6/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [7/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [8/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [9/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Epoch [10/10], Loss: 6848.7515, Val Loss: 7279.2077\n",
            "Model with the least loss saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "motion_blur_img[0].shape"
      ],
      "metadata": {
        "id": "dkBNIvuDdGGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZjEhJj5WAu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
